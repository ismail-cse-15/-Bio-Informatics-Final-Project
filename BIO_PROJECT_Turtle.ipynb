{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "SFiQswuE87ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **T5_BASE F1_Score**"
      ],
      "metadata": {
        "id": "m3ZsKuyaS98q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "# set up the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# load the pretrained model and tokenizer\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\").to(device)\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "\n",
        "# define the function to generate answers\n",
        "def generate_answer(question, context):\n",
        "    input_str = \"question: \" + question + \" context: \" + context #+ \" </s>\"\n",
        "    input_ids = tokenizer.encode(input_str, return_tensors=\"pt\").to(device)\n",
        "    outputs = model.generate(input_ids)\n",
        "    # print(\"Output\")\n",
        "    # print(tokenizer.decode(outputs[0]))\n",
        "    tem = tokenizer.decode(outputs[0])\n",
        "    ans = \"\"\n",
        "    n = len(tem)\n",
        "    f = True\n",
        "    for c in range(0,n):\n",
        "      if tem[c]=='<':\n",
        "        f = False\n",
        "      elif tem[c]=='>':\n",
        "        f = True\n",
        "      else:\n",
        "        if f==True:\n",
        "          ans = ans + tem[c]\n",
        "    print(ans)\n",
        "    return ans\n",
        "    # return tokenizer.decode(outputs[0])\n",
        "\n",
        "# define the function to calculate F1 score\n",
        "def calculate_f1_score(true_labels, predicted_labels):\n",
        "    return f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# example sentences\n",
        "sentences = [\n",
        "    \"Olive and Kemp’s are from same hypothetical_ancestor_ 1.\",\n",
        "    \"Hawksbill and hypothetical_ancestor_1 are from same hypothetical_ancestor_ 2.\",\n",
        "    \"Flatback and Green are from same hypothetical_ancestor_ 3 .\",\n",
        "    \"Leatherback and hypothetical_ancestor_3 are from same hypothetical_ancestor_ 4.\",\n",
        "    \"Loggerhead and hypothetical_ancestor_4 are from same hypothetical_ancestor_ 5.\",\n",
        "    \"hypothetical_ancestor_2 and hypothetical_ancestor_5 are from same hypothetical_ancestor_ 6.\"\n",
        "]\n",
        "\n",
        "questions = [\n",
        "    (\"Who is the parent of Olive?\",\"hypothetical_ancestor_ 1\"),\n",
        "    (\"Who is the parent of Kemp's?\",\"hypothetical_ancestor_ 1\"),\n",
        "    (\"Who is the parent of Olive and Kemp's?\",\"hypothetical_ancestor_ 1\"),\n",
        "    (\"Who are the parents of Hawksbill?\",\"hypothetical_ancestor_ 2\"),\n",
        "    (\"Who are the parents of Leatherback?\",\"hypothetical_ancestor_ 4\"),\n",
        "    (\"Who are the parents of Loggerhead ?\",\"hypothetical_ancestor_ 5\"),\n",
        "    (\"Who is the parent of Flatback and Green?\",\"hypothetical_ancestor_ 3\"),\n",
        "    (\"Who is the parent of Flatback?\",\"hypothetical_ancestor_ 3\"),\n",
        "    (\"Who is the parent of Green?\",\"hypothetical_ancestor_ 3\"),\n",
        "\n",
        "    (\"Who are the children of hypothetical_ancestor_1?\",\"Olive and Kemp’s\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_3?\",\"Flatback and Green\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_2?\",\"Hawksbill and hypothetical_ancestor_1\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_4?\",\"Leatherback and hypothetical_ancestor_3\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_5?\",\"Loggerhead and hypothetical_ancestor_4\"),\n",
        "\n",
        "    (\"What is the common ancestor of Olive and Kemp’s?\",\"hypothetical_ancestor_1\"),\n",
        "    (\"What is the common ancestor of Olive and Hawksbill?\",\"hypothetical_ancestor_ 2\"),\n",
        "    (\"What is the common ancestor of Olive,  Kemp’s and Hawksbill?\",\"hypothetical_ancestor_ 2\"),\n",
        "    (\"What is the common ancestor of Flatback and Green?\",\"hypothetical_ancestor_ 3\"),\n",
        "    (\"What is the common ancestor of Leatherback, Flatback and Green?\",\"hypothetical_ancestor_3\"),\n",
        "    (\"What is the common ancestor of Loggerhead, Leatherback, Flatback and Green?\",\"hypothetical_ancestor_4\")\n",
        "]\n",
        "\n",
        "# generate answers and calculate F1 score\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "for question in questions:\n",
        "    true_labels.append(question[1])\n",
        "    answer = generate_answer(question[0], ' '.join(sentences))\n",
        "    print(f\"Q: {question[0]}\")\n",
        "    print(f\"A: {answer}\")\n",
        "    predicted_labels.append(answer.strip())\n",
        "\n",
        "\n",
        "y_true = true_labels\n",
        "y_pred = predicted_labels\n",
        "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
        "precision = precision_score(y_true, y_pred, average=\"weighted\")\n",
        "recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
        "\n",
        "exact_match = 0\n",
        "n = len(y_true)\n",
        "for i in range(n):\n",
        "  if y_true[i]==y_pred[i]:\n",
        "    exact_match = exact_match + 1\n",
        "#exact_match = int(y_true == y_pred)\n",
        "\n",
        "# Print the output and metrics\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Exact Match:\", exact_match)"
      ],
      "metadata": {
        "id": "pOsbHwfSSacS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **T5_BioQA F1_Score**"
      ],
      "metadata": {
        "id": "X8LLgPHTUHaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Load the tokenizer and model\n",
        "import torch\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"ozcangundes/T5-base-for-BioQA\").to(device)\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"ozcangundes/T5-base-for-BioQA\")\n",
        "\n",
        "# define the function to generate answers\n",
        "def generate_answer(question, context):\n",
        "    input_str = \"question: \" + question + \" context: \" + context #+ \" </s>\"\n",
        "    input_ids = tokenizer.encode(input_str, return_tensors=\"pt\").to(device)\n",
        "    outputs = model.generate(input_ids)\n",
        "    # print(\"Output\")\n",
        "    # print(tokenizer.decode(outputs[0]))\n",
        "    tem = tokenizer.decode(outputs[0])\n",
        "    ans = \"\"\n",
        "    n = len(tem)\n",
        "    f = True\n",
        "    for c in range(0,n):\n",
        "      if tem[c]=='<':\n",
        "        f = False\n",
        "      elif tem[c]=='>':\n",
        "        f = True\n",
        "      else:\n",
        "        if f==True:\n",
        "          ans = ans + tem[c]\n",
        "    print(ans)\n",
        "    return ans\n",
        "    # return tokenizer.decode(outputs[0])\n",
        "\n",
        "# define the function to calculate F1 score\n",
        "def calculate_f1_score(true_labels, predicted_labels):\n",
        "    return f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# example sentences\n",
        "sentences = [\n",
        "    \"Olive and Kemp’s are from same hypothetical_ancestor_ 1.\",\n",
        "    \"Hawksbill and hypothetical_ancestor_1 are from same hypothetical_ancestor_ 2.\",\n",
        "    \"Flatback and Green are from same hypothetical_ancestor_ 3 .\",\n",
        "    \"Leatherback and hypothetical_ancestor_3 are from same hypothetical_ancestor_ 4.\",\n",
        "    \"Loggerhead and hypothetical_ancestor_4 are from same hypothetical_ancestor_ 5.\",\n",
        "    \"hypothetical_ancestor_2 and hypothetical_ancestor_5 are from same hypothetical_ancestor_ 6.\"\n",
        "]\n",
        "\n",
        "questions = [\n",
        "    (\"Who is the parent of Olive?\",\"hypothetical_ancestor_ 1\"),\n",
        "    (\"Who is the parent of Kemp's?\",\"same hypothetical_ancestor_ 1\"),\n",
        "    (\"Who is the parent of Olive and Kemp's?\",\"same hypothetical_ancestor_ 1\"),\n",
        "    (\"Who are the parents of Hawksbill?\",\"hypothetical_ancestor_ 2\"),\n",
        "    (\"Who are the parents of Leatherback?\",\"hypothetical_ancestor_ 4\"),\n",
        "    (\"Who are the parents of Loggerhead ?\",\"hypothetical_ancestor_ 5\"),\n",
        "    (\"Who is the parent of Flatback and Green?\",\"same hypothetical_ancestor_ 3\"),\n",
        "    (\"Who is the parent of Flatback?\",\"hypothetical_ancestor_ 3\"),\n",
        "    (\"Who is the parent of Green?\",\"same hypothetical_ancestor_ 3\"),\n",
        "\n",
        "    (\"Who are the children of hypothetical_ancestor_1?\",\"Olive and Kemp’s\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_3?\",\"Flatback and Green\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_2?\",\"Hawksbill, Olive and Kemp's\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_4?\",\"Leatherback and hypothetical_ancestor_3\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_5?\",\"Loggerhead and hypothetical_ancestor_4\"),\n",
        "\n",
        "    (\"What is the common ancestor of Olive and Kemp’s?\",\"hypothetical_ancestor_1\"),\n",
        "    (\"What is the common ancestor of Olive and Hawksbill?\",\"hypothetical_ancestor_ 2\"),\n",
        "    (\"What is the common ancestor of Olive,  Kemp’s and Hawksbill?\",\"hypothetical_ancestor_ 2\"),\n",
        "    (\"What is the common ancestor of Flatback and Green?\",\"hypothetical_ancestor_3\"),\n",
        "    (\"What is the common ancestor of Leatherback, Flatback and Green?\",\"hypothetical_ancestor_ 4\"),\n",
        "    (\"What is the common ancestor of Loggerhead, Leatherback, Flatback and Green?\",\"hypothetical_ancestor_ 5\")\n",
        "]\n",
        "\n",
        "# generate answers and calculate F1 score\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "for question in questions:\n",
        "    true_labels.append(question[1])\n",
        "    answer = generate_answer(question[0], ' '.join(sentences))\n",
        "    print(f\"Q: {question[0]}\")\n",
        "    print(f\"A: {answer}\")\n",
        "    predicted_labels.append(answer.strip())\n",
        "\n",
        "\n",
        "y_true = true_labels\n",
        "y_pred = predicted_labels\n",
        "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
        "precision = precision_score(y_true, y_pred, average=\"weighted\")\n",
        "recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
        "#exact_match = int(y_true == y_pred)\n",
        "exact_match = 0\n",
        "n = len(y_true)\n",
        "for i in range(n):\n",
        "  if y_true[i]==y_pred[i]:\n",
        "    exact_match = exact_match + 1\n",
        "\n",
        "# Print the output and metrics\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Exact Match:\", exact_match)"
      ],
      "metadata": {
        "id": "hWj_eVXOUFf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ALBERT F1_Score**"
      ],
      "metadata": {
        "id": "9eOmA-WtVkoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load ALBERT model and tokenizer\n",
        "model_name = \"mfeb/albert-xxlarge-v2-squad2\"\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name).to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# define the function to generate answers\n",
        "def generate_answer(question, context):\n",
        "    nlp = pipeline('question-answering', model=model, tokenizer=tokenizer, device=device)\n",
        "    result = nlp(question=question, context=context)\n",
        "    answer = result['answer']\n",
        "    return answer\n",
        "\n",
        "# define the function to calculate F1 score\n",
        "def calculate_f1_score(true_labels, predicted_labels):\n",
        "    return f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# example sentences\n",
        "sentences = [\n",
        "    \"Olive and Kemp’s are from same hypothetical_ancestor_ 1.\",\n",
        "    \"Hawksbill and hypothetical_ancestor_1 are from same hypothetical_ancestor_ 2.\",\n",
        "    \"Flatback and Green are from same hypothetical_ancestor_ 3 .\",\n",
        "    \"Leatherback and hypothetical_ancestor_3 are from same hypothetical_ancestor_ 4.\",\n",
        "    \"Loggerhead and hypothetical_ancestor_4 are from same hypothetical_ancestor_ 5.\",\n",
        "    \"hypothetical_ancestor_2 and hypothetical_ancestor_5 are from same hypothetical_ancestor_ 6.\"\n",
        "]\n",
        "\n",
        "\n",
        "questions = [\n",
        "    (\"Who is the parent of Olive?\",\"hypothetical_ancestor_ 1\"),\n",
        "    (\"Who is the parent of Kemp's?\",\"hypothetical_ancestor_1\"),\n",
        "    (\"Who is the parent of Olive and Kemp's?\",\"hypothetical_ancestor_1\"),\n",
        "    (\"Who are the parents of Hawksbill?\",\"hypothetical_ancestor_ 2\"),\n",
        "    (\"Who are the parents of Leatherback?\",\"hypothetical_ancestor_4\"),\n",
        "    (\"Who are the parents of Loggerhead ?\",\"hypothetical_ancestor_ 5\"),\n",
        "    (\"Who is the parent of Flatback and Green?\",\"hypothetical_ancestor_\"),\n",
        "    (\"Who is the parent of Flatback?\",\"hypothetical_ancestor_ 3\"),\n",
        "    (\"Who is the parent of Green?\",\"hypothetical_ancestor_ 3\"),\n",
        "\n",
        "    (\"Who are the children of hypothetical_ancestor_1?\",\"Olive and Kemp’s\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_3?\",\"Flatback and Green\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_2?\",\"Hawksbill and hypothetical_ancestor_1\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_4?\",\"Leatherback and hypothetical_ancestor_3\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_5?\",\"Loggerhead and hypothetical_ancestor_4\"),\n",
        "\n",
        "    (\"What is the common ancestor of Olive and Kemp’s?\",\"hypothetical_ancestor_ 1\"),\n",
        "    (\"What is the common ancestor of Olive and Hawksbill?\",\"hypothetical_ancestor_ 2\"),\n",
        "    (\"What is the common ancestor of Olive,  Kemp’s and Hawksbill?\",\"hypothetical_ancestor_ 2\"),\n",
        "    (\"What is the common ancestor of Flatback and Green?\",\"hypothetical_ancestor_ 3\"),\n",
        "    (\"What is the common ancestor of Leatherback, Flatback and Green?\",\"hypothetical_ancestor_ 4\"),\n",
        "    (\"What is the common ancestor of Loggerhead, Leatherback, Flatback and Green?\",\"hypothetical_ancestor_ 5\")\n",
        "]\n",
        "\n",
        "# generate answers and calculate F1 score\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "for question in questions:\n",
        "    true_labels.append(question[1])\n",
        "    answer = generate_answer(question[0], ' '.join(sentences))\n",
        "    print(f\"Q: {question[0]}\")\n",
        "    print(f\"A: {answer}\")\n",
        "    predicted_labels.append(answer.strip())\n",
        "\n",
        "y_true = true_labels\n",
        "y_pred = predicted_labels\n",
        "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
        "precision = precision_score(y_true, y_pred, average=\"weighted\")\n",
        "recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
        "#exact_match = int(y_true == y_pred)\n",
        "exact_match = 0\n",
        "n = len(y_true)\n",
        "for i in range(n):\n",
        "  if y_true[i]==y_pred[i]:\n",
        "    exact_match = exact_match + 1\n",
        "\n",
        "# Print the output and metrics\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Exact Match:\", exact_match)\n"
      ],
      "metadata": {
        "id": "L4nHIbpgNrm6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}