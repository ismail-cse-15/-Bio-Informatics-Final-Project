{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjJyaytckJM2"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "4lzvwQQxC2Ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# load the model\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "# set the prefix and suffix\n",
        "prefix = \"generate questions: \"\n",
        "suffix = \" </s>\"\n",
        "\n",
        "# create a list of sentences\n",
        "sentences = [\"GVA4_Java and GVA5_Java are from same hypothetical_ancestor_ 1.\",\n",
        "             \"hypothetical_ancestor_1 and GVA6_Java are from same hypothetical_ancestor_ 2.\",\n",
        "             \"hypothetical_ancestor_2 and GVAB_Borneo are from same hypothetical_ancestor_ 3.\",\n",
        "             \"GVA2_Malay_Penninsula and GVA3_Malay_Penninsula are from same hypothetical_ancestor_ 4.\",\n",
        "             \"GVA1_Malay_Penninsula and hypothetical_ancestor_4 are from same hypothetical_ancestor_ 5.\",\n",
        "             \"hypothetical_ancestor_3 and hypothetical_ancestor_5 are from same hypothetical_ancestor_ 6.\"]\n",
        "\n",
        "# create empty lists for questions and references\n",
        "questions = []\n",
        "references = []\n",
        "\n",
        "# generate questions\n",
        "for sentence in sentences:\n",
        "    input_text = prefix + sentence + suffix\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "    outputs = model.generate(input_ids)\n",
        "    question = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    questions.append(question)\n",
        "    \n",
        "    # add reference for calculating F1 score\n",
        "    reference = sentence.split(\" and \")[0].replace(\".\", \"\")\n",
        "    references.append(reference)\n",
        "    \n",
        "# print questions and references\n",
        "print(\"Generated Questions:\")\n",
        "print(questions)\n",
        "print(\"\\nReferences:\")\n",
        "print(references)\n",
        "\n",
        "# calculate F1 score\n",
        "f1 = f1_score(references, questions, average='macro')\n",
        "print(\"\\nF1 Score:\", f1)\n"
      ],
      "metadata": {
        "id": "Y55vMW4t8D0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **T5_BASE F1_Score**"
      ],
      "metadata": {
        "id": "m3ZsKuyaS98q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# set up the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# load the pretrained model and tokenizer\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\").to(device)\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "\n",
        "# define the function to generate answers\n",
        "def generate_answer(question, context):\n",
        "    input_str = \"question: \" + question + \" context: \" + context #+ \" </s>\"\n",
        "    input_ids = tokenizer.encode(input_str, return_tensors=\"pt\").to(device)\n",
        "    outputs = model.generate(input_ids)\n",
        "    # print(\"Output\")\n",
        "    # print(tokenizer.decode(outputs[0]))\n",
        "    tem = tokenizer.decode(outputs[0])\n",
        "    ans = \"\"\n",
        "    n = len(tem)\n",
        "    f = True\n",
        "    for c in range(0,n):\n",
        "      if tem[c]=='<':\n",
        "        f = False\n",
        "      elif tem[c]=='>':\n",
        "        f = True\n",
        "      else:\n",
        "        if f==True:\n",
        "          ans = ans + tem[c]\n",
        "    print(ans)\n",
        "    return ans\n",
        "    # return tokenizer.decode(outputs[0])\n",
        "\n",
        "# define the function to calculate F1 score\n",
        "def calculate_f1_score(true_labels, predicted_labels):\n",
        "    return f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# example sentences\n",
        "sentences = [\n",
        "    \"GVA4_Java and GVA5_Java are from same hypothetical_ancestor_ 1 .\",\n",
        "    \"hypothetical_ancestor_1 and GVA6_Java are from same hypothetical_ancestor_ 2 .\",\n",
        "    \"hypothetical_ancestor_2 and GVAB_Borneo are from same hypothetical_ancestor_ 3 .\",\n",
        "    \"GVA2_Malay_Penninsula and GVA3_Malay_Penninsula are from same hypothetical_ancestor_ 4 .\",\n",
        "    \"GVA1_Malay_Penninsula and hypothetical_ancestor_4 are from same hypothetical_ancestor_ 5 .\",\n",
        "    \"hypothetical_ancestor_3 and hypothetical_ancestor_5 are from same hypothetical_ancestor_ 6 .\"\n",
        "]\n",
        "\n",
        "\n",
        "questions = [\n",
        "    (\"Who are the parent of GVA4_Java?\", \"hypothetical_ancestor_ 1\"),\n",
        "    (\"Who is the parent of GVA5_Java?\", \"hypothetical_ancestor_ 1\"),\n",
        "    (\"Who is the parent of GVA4_Java and GVA5_Java?\", \"hypothetical_ancestor_ 1\"),\n",
        "    (\"Who is the parent of GVA6_Java?\", \"hypothetical_ancestor_ 2\"),\n",
        "    (\"Who is the parent of GVAB_Borneo?\", \"hypothetical_ancestor_ 3\"),\n",
        "    (\"Who is the parent of GVA2_Malay_Penninsula?\", \"hypothetical_ancestor_ 4\"),\n",
        "    (\"Who is the parent of GVA3_Malay_Penninsula?\", \"hypothetical_ancestor_ 4\"),\n",
        "    (\"Who is the parent of GVA1_Malay_Penninsula?\", \"hypothetical_ancestor_ 5\"),\n",
        "    (\"Who is the parent of GVA2_Malay_Penninsula and GVA3_Malay_Penninsula?\", \"hypothetical_ancestor_ 4\"),\n",
        "\n",
        "    (\"Who are the children of hypothetical_ancestor_2?\", \"hypothetical_ancestor_1 and GVA6_Java\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_4?\", \"GVA2_Malay_Penninsula and GVA3_Malay_Penninsula\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_1?\", \"GVA4_Java and GVA5_Java\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_3?\", \"hypothetical_ancestor_2 and GVAB_Borneo\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_5?\", \"GVA1_Malay_Penninsula and hypothetical_ancestor_4\"),\n",
        "\n",
        "    (\"What is the common ancestor of GVA1_Malay_Penninsula and GVA3_Malay_Penninsula?\", \"hypothetical_ancestor_ 5\"),\n",
        "    (\"What is the common ancestor of GVA1_Malay_Penninsula,  GVA2_Malay_Penninsula and GVA3_Malay_Penninsula?\", \"hypothetical_ancestor_ 5\"),\n",
        "    (\"What is the common ancestor of GVA2_Malay_Penninsula and GVA3_Malay_Penninsula?\", \"hypothetical_ancestor_ 4\"),\n",
        "    (\"What is the common ancestor of GVA2_Malay_Penninsula and GVA1_Malay_Penninsula?\", \"hypothetical_ancestor_ 5\"),\n",
        "    (\"What is the common ancestor of GVA4_Java and GVA5_Java?\", \"hypothetical_ancestor_ 1\"),\n",
        "    (\"What is the common ancestor of GVA4_Java and GVA6_Java?\", \"hypothetical_ancestor_ 2\"),\n",
        "    (\"What is the common ancestor of GVA6_Java and GVA5_Java?\", \"hypothetical_ancestor_ 2\"),\n",
        "    (\"What is the common ancestor of GVA4_Java, GVA5_Java and GVA6_Java?\", \"hypothetical_ancestor_ 2\"),\n",
        "    (\"What is the common ancestor of GVAB_Borneo and GVA6_Java?\", \"hypothetical_ancestor_ 3\"),\n",
        "    (\"What is the common ancestor of GVAB_Borneo, GVA4_java, GVA5_Java and GVA6_Java?\", \"hypothetical_ancestor_ 3\"),\n",
        "    (\"What is the common ancestor of GVAB_Borneo, GVA4_java, GVA5_Java?\", \"hypothetical_ancestor_ 3\")\n",
        "]\n",
        "\n",
        "# generate answers and calculate F1 score\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "for question in questions:\n",
        "    true_labels.append(question[1])\n",
        "    answer = generate_answer(question[0], ' '.join(sentences))\n",
        "    print(f\"Q: {question[0]}\")\n",
        "    print(f\"A: {answer}\")\n",
        "    predicted_labels.append(answer.strip())\n",
        "\n",
        "f1 = calculate_f1_score(true_labels, predicted_labels)\n",
        "# print(\"True Label\")\n",
        "# print(true_labels)\n",
        "# print(\"Predicted Label\")\n",
        "# print(predicted_labels)\n",
        "print(f\"F1 score: {f1}\")"
      ],
      "metadata": {
        "id": "eVYIqpkTGJcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "# set up the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# load the pretrained model and tokenizer\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\").to(device)\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "\n",
        "# define the function to generate answers\n",
        "def generate_answer(question, context):\n",
        "    input_str = \"question: \" + question + \" context: \" + context #+ \" </s>\"\n",
        "    input_ids = tokenizer.encode(input_str, return_tensors=\"pt\").to(device)\n",
        "    outputs = model.generate(input_ids)\n",
        "    # print(\"Output\")\n",
        "    # print(tokenizer.decode(outputs[0]))\n",
        "    tem = tokenizer.decode(outputs[0])\n",
        "    ans = \"\"\n",
        "    n = len(tem)\n",
        "    f = True\n",
        "    for c in range(0,n):\n",
        "      if tem[c]=='<':\n",
        "        f = False\n",
        "      elif tem[c]=='>':\n",
        "        f = True\n",
        "      else:\n",
        "        if f==True:\n",
        "          ans = ans + tem[c]\n",
        "    print(ans)\n",
        "    return ans\n",
        "    # return tokenizer.decode(outputs[0])\n",
        "\n",
        "# define the function to calculate F1 score\n",
        "def calculate_f1_score(true_labels, predicted_labels):\n",
        "    return f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# example sentences\n",
        "sentences = [\n",
        "    \"GVA4_Java and GVA5_Java are from same hypothetical_ancestor_ 1 .\",\n",
        "    \"hypothetical_ancestor_1 and GVA6_Java are from same hypothetical_ancestor_ 2 .\",\n",
        "    \"hypothetical_ancestor_2 and GVAB_Borneo are from same hypothetical_ancestor_ 3 .\",\n",
        "    \"GVA2_Malay_Penninsula and GVA3_Malay_Penninsula are from same hypothetical_ancestor_ 4 .\",\n",
        "    \"GVA1_Malay_Penninsula and hypothetical_ancestor_4 are from same hypothetical_ancestor_ 5 .\",\n",
        "    \"hypothetical_ancestor_3 and hypothetical_ancestor_5 are from same hypothetical_ancestor_ 6 .\"\n",
        "]\n",
        "\n",
        "questions = [\n",
        "    (\"Who are the parent of GVA4_Java?\", \"hypothetical_ancestor_ 1\"),\n",
        "    (\"Who is the parent of GVA5_Java?\", \"hypothetical_ancestor_ 1\"),\n",
        "    (\"Who is the parent of GVA4_Java and GVA5_Java?\", \"hypothetical_ancestor_ 1\"),\n",
        "    (\"Who is the parent of GVA6_Java?\", \"hypothetical_ancestor_2\"),\n",
        "    (\"Who is the parent of GVAB_Borneo?\", \"hypothetical_ancestor_ 3\"),\n",
        "    (\"Who is the parent of GVA2_Malay_Penninsula?\", \"hypothetical_ancestor_ 4\"),\n",
        "    (\"Who is the parent of GVA3_Malay_Penninsula?\", \"hypothetical_ancestor_ 4\"),\n",
        "    (\"Who is the parent of GVA1_Malay_Penninsula?\", \"hypothetical_ancestor_5\"),\n",
        "    (\"Who is the parent of GVA2_Malay_Penninsula and GVA3_Malay_Penninsula?\", \"hypothetical_ancestor_ 4\"),\n",
        "\n",
        "    (\"Who are the children of hypothetical_ancestor_2?\", \"hypothetical_ancestor_1 and GVA6_Java\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_4?\", \"GVA2_Malay_Penninsula and GVA3_Malay_Penninsula\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_1?\", \"GVA4_Java and GVA5_Java\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_3?\", \"hypothetical_ancestor_2 and GVAB_Borneo\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_5?\", \"GVA1_Malay_Penninsula and hypothetical_ancestor_4\"),\n",
        "\n",
        "    (\"What is the common ancestor of GVA1_Malay_Penninsula and GVA3_Malay_Penninsula?\", \"hypothetical_ancestor_ 5\"),\n",
        "    (\"What is the common ancestor of GVA1_Malay_Penninsula,  GVA2_Malay_Penninsula and GVA3_Malay_Penninsula?\", \"hypothetical_ancestor_ 5\"),\n",
        "    (\"What is the common ancestor of GVA2_Malay_Penninsula and GVA3_Malay_Penninsula?\", \"hypothetical_ancestor_ 4\"),\n",
        "    (\"What is the common ancestor of GVA2_Malay_Penninsula and GVA1_Malay_Penninsula?\", \"hypothetical_ancestor_ 5\"),\n",
        "    (\"What is the common ancestor of GVA4_Java and GVA5_Java?\", \"hypothetical_ancestor_ 1\"),\n",
        "    (\"What is the common ancestor of GVA4_Java and GVA6_Java?\", \"hypothetical_ancestor_ 2\"),\n",
        "    (\"What is the common ancestor of GVA6_Java and GVA5_Java?\", \"hypothetical_ancestor_ 2\"),\n",
        "    (\"What is the common ancestor of GVA4_Java, GVA5_Java and GVA6_Java?\", \"hypothetical_ancestor_ 2\"),\n",
        "    (\"What is the common ancestor of GVAB_Borneo and GVA6_Java?\", \"hypothetical_ancestor_ 3\"),\n",
        "    (\"What is the common ancestor of GVAB_Borneo, GVA4_java, GVA5_Java and GVA6_Java?\", \"hypothetical_ancestor_ 3\"),\n",
        "    (\"What is the common ancestor of GVAB_Borneo, GVA4_java, GVA5_Java?\", \"hypothetical_ancestor_ 3\")\n",
        "]\n",
        "\n",
        "# generate answers and calculate F1 score\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "for question in questions:\n",
        "    true_labels.append(question[1])\n",
        "    answer = generate_answer(question[0], ' '.join(sentences))\n",
        "    print(f\"Q: {question[0]}\")\n",
        "    print(f\"A: {answer}\")\n",
        "    predicted_labels.append(answer.strip())\n",
        "\n",
        "\n",
        "y_true = true_labels\n",
        "y_pred = predicted_labels\n",
        "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
        "precision = precision_score(y_true, y_pred, average=\"weighted\")\n",
        "recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
        "\n",
        "exact_match = 0\n",
        "n = len(y_true)\n",
        "for i in range(n):\n",
        "  if y_true[i]==y_pred[i]:\n",
        "    exact_match = exact_match + 1\n",
        "#exact_match = int(y_true == y_pred)\n",
        "\n",
        "# Print the output and metrics\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Exact Match:\", exact_match)"
      ],
      "metadata": {
        "id": "pOsbHwfSSacS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **T5_BioQA F1_Score**"
      ],
      "metadata": {
        "id": "X8LLgPHTUHaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Load the tokenizer and model\n",
        "import torch\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"ozcangundes/T5-base-for-BioQA\").to(device)\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"ozcangundes/T5-base-for-BioQA\")\n",
        "\n",
        "# set up the device\n",
        "\n",
        "# load the pretrained model and tokenizer\n",
        "# model = T5ForConditionalGeneration.from_pretrained(\"t5-base\").to(device)\n",
        "# tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "\n",
        "\n",
        "# define the function to generate answers\n",
        "def generate_answer(question, context):\n",
        "    input_str = \"question: \" + question + \" context: \" + context #+ \" </s>\"\n",
        "    input_ids = tokenizer.encode(input_str, return_tensors=\"pt\").to(device)\n",
        "    outputs = model.generate(input_ids)\n",
        "    # print(\"Output\")\n",
        "    # print(tokenizer.decode(outputs[0]))\n",
        "    tem = tokenizer.decode(outputs[0])\n",
        "    ans = \"\"\n",
        "    n = len(tem)\n",
        "    f = True\n",
        "    for c in range(0,n):\n",
        "      if tem[c]=='<':\n",
        "        f = False\n",
        "      elif tem[c]=='>':\n",
        "        f = True\n",
        "      else:\n",
        "        if f==True:\n",
        "          ans = ans + tem[c]\n",
        "    print(ans)\n",
        "    return ans\n",
        "    # return tokenizer.decode(outputs[0])\n",
        "\n",
        "# define the function to calculate F1 score\n",
        "def calculate_f1_score(true_labels, predicted_labels):\n",
        "    return f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# example sentences\n",
        "sentences = [\n",
        "    \"GVA4_Java and GVA5_Java are from same hypothetical_ancestor_ 1 .\",\n",
        "    \"hypothetical_ancestor_1 and GVA6_Java are from same hypothetical_ancestor_ 2 .\",\n",
        "    \"hypothetical_ancestor_2 and GVAB_Borneo are from same hypothetical_ancestor_ 3 .\",\n",
        "    \"GVA2_Malay_Penninsula and GVA3_Malay_Penninsula are from same hypothetical_ancestor_ 4 .\",\n",
        "    \"GVA1_Malay_Penninsula and hypothetical_ancestor_4 are from same hypothetical_ancestor_ 5 .\",\n",
        "    \"hypothetical_ancestor_3 and hypothetical_ancestor_5 are from same hypothetical_ancestor_ 6 .\"\n",
        "]\n",
        "\n",
        "\n",
        "questions = [\n",
        "    (\"Who are the parent of GVA4_Java?\", \"hypothetical_ancestor_ 1\"),\n",
        "    (\"Who is the parent of GVA5_Java?\", \"hypothetical_ancestor_ 1\"),\n",
        "    (\"Who is the parent of GVA4_Java and GVA5_Java?\", \"same hypothetical_ancestor_ 1\"),\n",
        "    (\"Who is the parent of GVA6_Java?\", \"hypothetical_ancestor_ 2\"),\n",
        "    (\"Who is the parent of GVAB_Borneo?\", \"hypothetical_ancestor_3\"),\n",
        "    (\"Who is the parent of GVA2_Malay_Penninsula?\", \"hypothetical_ancestor_ 4\"),\n",
        "    (\"Who is the parent of GVA3_Malay_Penninsula?\", \"hypothetical_ancestor_ 4\"),\n",
        "    (\"Who is the parent of GVA1_Malay_Penninsula?\", \"hypothetical_ancestor_ 5\"),\n",
        "    (\"Who is the parent of GVA2_Malay_Penninsula and GVA3_Malay_Penninsula?\", \"same hypothetical_ancestor_ 4\"),\n",
        "\n",
        "    (\"Who are the children of hypothetical_ancestor_2?\", \"hypothetical_ancestor_1 and GVA6_Java\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_4?\", \"GVA2_Malay_Penninsula and GVA3_Malay_Penninsula\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_1?\", \"GVA4_Java and GVA5_Java\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_3?\", \"GVAB_Borneo\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_5?\", \"GVA1_Malay_Penninsula and hypothetical_ancestor_4\"),\n",
        "\n",
        "    (\"What is the common ancestor of GVA1_Malay_Penninsula and GVA3_Malay_Penninsula?\", \"hypothetical_ancestor_ 5\"),\n",
        "    (\"What is the common ancestor of GVA1_Malay_Penninsula,  GVA2_Malay_Penninsula and GVA3_Malay_Penninsula?\", \"hypothetical_ancestor_ 5\"),\n",
        "    (\"What is the common ancestor of GVA2_Malay_Penninsula and GVA3_Malay_Penninsula?\", \"same hypothetical_ancestor_ 4\"),\n",
        "    (\"What is the common ancestor of GVA2_Malay_Penninsula and GVA1_Malay_Penninsula?\", \"hypothetical_ancestor_ 5\"),\n",
        "    (\"What is the common ancestor of GVA4_Java and GVA5_Java?\", \"hypothetical_ancestor_ 1\"),\n",
        "    (\"What is the common ancestor of GVA4_Java and GVA6_Java?\", \"hypothetical_ancestor_ 2\"),\n",
        "    (\"What is the common ancestor of GVA6_Java and GVA5_Java?\", \"hypothetical_ancestor_ 2\"),\n",
        "    (\"What is the common ancestor of GVA4_Java, GVA5_Java and GVA6_Java?\", \"hypothetical_ancestor_ 2\"),\n",
        "    (\"What is the common ancestor of GVAB_Borneo and GVA6_Java?\", \"hypothetical_ancestor_ 3\"),\n",
        "    (\"What is the common ancestor of GVAB_Borneo, GVA4_java, GVA5_Java and GVA6_Java?\", \"hypothetical_ancestor_ 3\"),\n",
        "    (\"What is the common ancestor of GVAB_Borneo, GVA4_java, GVA5_Java?\", \"hypothetical_ancestor_ 3\")\n",
        "]\n",
        "\n",
        "# generate answers and calculate F1 score\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "for question in questions:\n",
        "    true_labels.append(question[1])\n",
        "    answer = generate_answer(question[0], ' '.join(sentences))\n",
        "    print(f\"Q: {question[0]}\")\n",
        "    print(f\"A: {answer}\")\n",
        "    predicted_labels.append(answer.strip())\n",
        "\n",
        "\n",
        "y_true = true_labels\n",
        "y_pred = predicted_labels\n",
        "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
        "precision = precision_score(y_true, y_pred, average=\"weighted\")\n",
        "recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
        "#exact_match = int(y_true == y_pred)\n",
        "exact_match = 0\n",
        "n = len(y_true)\n",
        "for i in range(n):\n",
        "  if y_true[i]==y_pred[i]:\n",
        "    exact_match = exact_match + 1\n",
        "\n",
        "# Print the output and metrics\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Exact Match:\", exact_match)"
      ],
      "metadata": {
        "id": "hWj_eVXOUFf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ALBERT F1_Score**"
      ],
      "metadata": {
        "id": "9eOmA-WtVkoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load ALBERT model and tokenizer\n",
        "model_name = \"mfeb/albert-xxlarge-v2-squad2\"\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name).to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# define the function to generate answers\n",
        "def generate_answer(question, context):\n",
        "    nlp = pipeline('question-answering', model=model, tokenizer=tokenizer, device=device)\n",
        "    result = nlp(question=question, context=context)\n",
        "    answer = result['answer']\n",
        "    return answer\n",
        "\n",
        "# define the function to calculate F1 score\n",
        "def calculate_f1_score(true_labels, predicted_labels):\n",
        "    return f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# example sentences\n",
        "sentences = [\n",
        "    \"GVA4_Java and GVA5_Java are from same hypothetical_ancestor_ 1 .\",\n",
        "    \"hypothetical_ancestor_1 and GVA6_Java are from same hypothetical_ancestor_ 2 .\",\n",
        "    \"hypothetical_ancestor_2 and GVAB_Borneo are from same hypothetical_ancestor_ 3 .\",\n",
        "    \"GVA2_Malay_Penninsula and GVA3_Malay_Penninsula are from same hypothetical_ancestor_ 4 .\",\n",
        "    \"GVA1_Malay_Penninsula and hypothetical_ancestor_4 are from same hypothetical_ancestor_ 5 .\",\n",
        "    \"hypothetical_ancestor_3 and hypothetical_ancestor_5 are from same hypothetical_ancestor_ 6 .\"\n",
        "]\n",
        "\n",
        "questions = [\n",
        "    (\"Who are the parent of GVA4_Java?\", \"hypothetical_ancestor_1\"),\n",
        "    (\"Who is the parent of GVA5_Java?\", \"hypothetical_ancestor_1\"),\n",
        "    (\"Who is the parent of GVA4_Java and GVA5_Java?\", \"hypothetical_ancestor_1\"),\n",
        "    (\"Who is the parent of GVA6_Java?\", \"hypothetical_ancestor_2\"),\n",
        "    (\"Who is the parent of GVAB_Borneo?\", \"hypothetical_ancestor_ 3\"),\n",
        "    (\"Who is the parent of GVA2_Malay_Penninsula?\", \"hypothetical_ancestor_ 4\"),\n",
        "    (\"Who is the parent of GVA3_Malay_Penninsula?\", \"hypothetical_ancestor_ 4\"),\n",
        "    (\"Who is the parent of GVA1_Malay_Penninsula?\", \"hypothetical_ancestor_ 5\"),\n",
        "    (\"Who is the parent of GVA2_Malay_Penninsula and GVA3_Malay_Penninsula?\", \"hypothetical_ancestor_ 4\"),\n",
        "\n",
        "    (\"Who are the children of hypothetical_ancestor_2?\", \"hypothetical_ancestor_1 and GVA6_Java\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_4?\", \"GVA2_Malay_Penninsula and GVA3_Malay_Penninsula\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_1?\", \"GVA4_Java and GVA5_Java\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_3?\", \"hypothetical_ancestor_2 and GVAB_Borneo\"),\n",
        "    (\"Who are the children of hypothetical_ancestor_5?\", \"GVA1_Malay_Penninsula and hypothetical_ancestor_4\"),\n",
        "\n",
        "    (\"What is the common ancestor of GVA1_Malay_Penninsula and GVA3_Malay_Penninsula?\", \"hypothetical_ancestor_ 5\"),\n",
        "    (\"What is the common ancestor of GVA1_Malay_Penninsula,  GVA2_Malay_Penninsula and GVA3_Malay_Penninsula?\", \"hypothetical_ancestor_ 5\"),\n",
        "    (\"What is the common ancestor of GVA2_Malay_Penninsula and GVA3_Malay_Penninsula?\", \"hypothetical_ancestor_ 4\"),\n",
        "    (\"What is the common ancestor of GVA2_Malay_Penninsula and GVA1_Malay_Penninsula?\", \"hypothetical_ancestor_ 5\"),\n",
        "    (\"What is the common ancestor of GVA4_Java and GVA5_Java?\", \"hypothetical_ancestor_ 1\"),\n",
        "    (\"What is the common ancestor of GVA4_Java and GVA6_Java?\", \"hypothetical_ancestor_ 2\"),\n",
        "    (\"What is the common ancestor of GVA6_Java and GVA5_Java?\", \"hypothetical_ancestor_ 2\"),\n",
        "    (\"What is the common ancestor of GVA4_Java, GVA5_Java and GVA6_Java?\", \"hypothetical_ancestor_ \"),\n",
        "    (\"What is the common ancestor of GVAB_Borneo and GVA6_Java?\", \"hypothetical_ancestor_\"),\n",
        "    (\"What is the common ancestor of GVAB_Borneo, GVA4_java, GVA5_Java and GVA6_Java?\", \"hypothetical_ancestor_ \"),\n",
        "    (\"What is the common ancestor of GVAB_Borneo, GVA4_java, GVA5_Java?\", \"hypothetical_ancestor_ 3\")\n",
        "]\n",
        "\n",
        "# generate answers and calculate F1 score\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "for question in questions:\n",
        "    true_labels.append(question[1])\n",
        "    answer = generate_answer(question[0], ' '.join(sentences))\n",
        "    print(f\"Q: {question[0]}\")\n",
        "    print(f\"A: {answer}\")\n",
        "    predicted_labels.append(answer.strip())\n",
        "\n",
        "y_true = true_labels\n",
        "y_pred = predicted_labels\n",
        "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
        "precision = precision_score(y_true, y_pred, average=\"weighted\")\n",
        "recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
        "#exact_match = int(y_true == y_pred)\n",
        "exact_match = 0\n",
        "n = len(y_true)\n",
        "for i in range(n):\n",
        "  if y_true[i]==y_pred[i]:\n",
        "    exact_match = exact_match + 1\n",
        "\n",
        "# Print the output and metrics\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Exact Match:\", exact_match)\n"
      ],
      "metadata": {
        "id": "L4nHIbpgNrm6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}